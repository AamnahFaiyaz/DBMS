{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AamnahFaiyaz/DBMS/blob/main/Generative_AI_with_GPT_1_3_for_Story_Creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Xj9wXc8RnB6"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install required libraries\n",
        "!pip install transformers --quiet\n",
        "!pip install torch --quiet\n",
        "!pip install fpdf --quiet  # For PDF saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9Y9o7oBRn7A"
      },
      "outputs": [],
      "source": [
        "# Step 2: Import libraries\n",
        "from transformers import pipeline, set_seed\n",
        "import re\n",
        "from fpdf import FPDF\n",
        "import os\n",
        "from IPython.display import FileLink"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4Xi1DhaRqg-",
        "outputId": "c51cb819-b113-4b34-8541-ab02d11e14a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Loading model... This may take a few seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Model loaded!\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Setup model\n",
        "print(\"üîÑ Loading model... This may take a few seconds.\")\n",
        "generator = pipeline(\"text-generation\", model=\"EleutherAI/gpt-neo-1.3B\")\n",
        "set_seed(42)\n",
        "print(\"‚úÖ Model loaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGlp4VPhUJwU",
        "outputId": "2e19d88f-15a2-403d-a299-52d1a5a217e4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=715) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üß† Generating story...\n",
            "\n",
            "üìñ Generated Story:\n",
            "--------------------------------------------------\n",
            "I was walking through the misty forest and came upon this sign. ‚ÄúBehold the Tree of Life, a great red, majestic old tree. At its foot I planted an everlasting spring of water.‚Äù I was stunned! This tree, to which we have come to worship, was the very tree that I planted in the earth long ago, to provide the water of life! I sat down on the ground to contemplate this profound truth. The Spirit said to me, ‚ÄúThis spirit here is like you.‚Äù ‚ÄúHow can a spirit like this be your teacher?‚Äù ‚ÄúIs there a difference between us teachers of different spirits?‚Äù ‚ÄúI know that you know that this spirit is to me as the teacher of the Father, and the spirit whom he teaches as his disciples.‚Äù ‚ÄúIs it not the same spirit that is teaching the disciples of the Father?‚Äù ‚ÄúYou will know that this spirit has taught me as his disciple.‚Äù This tree is so much more powerful than any of the men\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Story generator loop\n",
        "while True:\n",
        "    prompt = input(\"‚úçÔ∏è Enter the beginning of the story: \")\n",
        "    try:\n",
        "        word_limit = int(input(\"üî¢ Enter the word limit for the story: \"))\n",
        "    except:\n",
        "        print(\"‚ùå Please enter a valid number.\")\n",
        "        continue\n",
        "\n",
        "    # Estimate max tokens (~0.75 tokens/word)\n",
        "    max_tokens = int(word_limit * 1.3)\n",
        "\n",
        "    # Generate the story\n",
        "    print(\"\\nüß† Generating story...\\n\")\n",
        "    result = generator(prompt, max_length=max_tokens, do_sample=True, temperature=0.9)[0]['generated_text']\n",
        "\n",
        "    # Trim the story to word limit\n",
        "    words = result.split()\n",
        "    trimmed_story = ' '.join(words[:word_limit])\n",
        "\n",
        "    # Display the story as a paragraph\n",
        "    print(\"üìñ Generated Story:\\n\" + \"-\"*50)\n",
        "    print(trimmed_story)\n",
        "    print(\"-\"*50)\n",
        "\n",
        "    # Ask to continue or stop\n",
        "    again = input(\"\\nüîÅ Do you want to write another story? (yes/no): \").strip().lower()\n",
        "    if again != \"yes\":\n",
        "        print(\"üëã Thank you for using the story generator!\")\n",
        "        break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOkf+XtRVNttMiaP/gsDYG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}